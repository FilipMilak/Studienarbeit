{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import expand_dims\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from skimage.transform import resize\n",
    "from IPython.display import SVG\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.utils import to_categorical, model_to_dot, plot_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = \"./stanford_dogs/\"\n",
    "img_width, img_height = 224, 224 \n",
    "channels = 3\n",
    "batch_size = 64\n",
    "num_images= 50\n",
    "image_arr_size= img_width * img_height * channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(image_dir):\n",
    "\n",
    "    image_index = 0\n",
    "    images = np.ndarray(shape=(num_images, image_arr_size))\n",
    "    labels = np.array([])                       \n",
    "\n",
    "    for type in os.listdir(image_dir)[:50]:\n",
    "        type_images = os.listdir(image_dir + type)\n",
    "        labels= np.append(labels, type.split('-')[1])\n",
    "        \n",
    "        for image in type_images[:1]:\n",
    "            image_file = os.path.join(image_dir, type + '/', image)\n",
    "            image_data = mpimg.imread(image_file)\n",
    "            image_resized = resize(image_data, (img_width, img_height), anti_aliasing=True)\n",
    "            images[image_index, :] = image_resized.flatten()\n",
    "            print (type, ':', image)\n",
    "            image_index += 1\n",
    "\n",
    "    return (images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale= 1./255,\n",
    "    shear_range= 0.2,\n",
    "    zoom_range= 0.2,\n",
    "    horizontal_flip= True,\n",
    "    rotation_range= 20,\n",
    "    width_shift_range= 0.2,\n",
    "    height_shift_range= 0.2,   \n",
    "    validation_split=0.2,\n",
    ")\n",
    "\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    rescale= 1./255, \n",
    "    validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16508 images belonging to 120 classes.\n",
      "Found 4072 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(  \n",
    "    train_data_dir,  \n",
    "    target_size= (img_width, img_height), \n",
    "    color_mode= 'rgb',\n",
    "    batch_size= batch_size,  \n",
    "    class_mode= 'categorical',\n",
    "    subset='training',\n",
    "    shuffle= True, \n",
    "    seed= 1337\n",
    ") \n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size= (img_width, img_height),\n",
    "    color_mode= 'rgb',\n",
    "    batch_size= batch_size,  \n",
    "    class_mode= 'categorical',\n",
    "    subset='validation',\n",
    "    shuffle= True, \n",
    "    seed= 1337\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(train_generator.class_indices)  \n",
    "train_labels = train_generator.classes \n",
    "train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
    "valid_labels = valid_generator.classes \n",
    "valid_labels = to_categorical(valid_labels, num_classes=num_classes)\n",
    "nb_train_samples = len(train_generator.filenames)  \n",
    "nb_valid_samples = len(valid_generator.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InceptionV3 = applications.InceptionV3(include_top= False, input_shape= (img_width, img_height, channels), weights= 'imagenet')\n",
    "InceptionV3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "for layer in InceptionV3.layers:\n",
    "    layer.trainable= False\n",
    "\n",
    "model.add(InceptionV3)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(120,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= keras.optimizers.Adam(lr= 0.0001), loss= 'categorical_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.001,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    mode='auto'\n",
    ")\n",
    "\n",
    "reduceLR = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=3,\n",
    "    verbose=1, \n",
    "    mode='auto'\n",
    ")\n",
    "\n",
    "callbacks = [earlystop, reduceLR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator, \n",
    "    epochs = 30,\n",
    "    steps_per_epoch = nb_train_samples//batch_size,\n",
    "    validation_data = valid_generator, \n",
    "    validation_steps = nb_valid_samples//batch_size,\n",
    "    verbose = 2, \n",
    "    callbacks = callbacks,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(eval_loss, eval_accuracy) = model.evaluate(valid_generator, batch_size= batch_size, verbose= 1)\n",
    "print('Validation Loss: ', eval_loss)\n",
    "print('Validation Accuracy: ', eval_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot()\n",
    "plt.title('Model Accuracy')\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Training Accuracy','Validation Accuracy'])\n",
    "plt.savefig('baseline_acc_epoch.png', transparent= False, bbox_inches= 'tight', dpi= 900)\n",
    "plt.show()\n",
    "\n",
    "plt.title('Model Loss')\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Training Loss','Validation Loss'])\n",
    "plt.savefig('baseline_loss_epoch.png', transparent= False, bbox_inches= 'tight', dpi= 900)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "studienarbeit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a19529e37f9af31a72dba3fad5ac5c951d1611ed0d963e2abf43bb8da3ac970"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
