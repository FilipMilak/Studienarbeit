{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to install the required packages for the snn conversion, \n",
    "# you need the following packages\n",
    "# furthemore you must have installed miniconda or anaconda\n",
    "# and activated a virtual environment to execute the following commands\n",
    "\n",
    "# %conda install akida\n",
    "# %conda install cnn2snn\n",
    "# %conda install akida-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " Tensor(\"args_0:0\", shape=(None, 4), dtype=float32) \n",
      "\n",
      " Tensor(\"strided_slice:0\", shape=(), dtype=int32) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Tensor(\"args_0:0\", shape=(None, 4), dtype=float32) \n",
      "\n",
      " Tensor(\"strided_slice:0\", shape=(), dtype=int32) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Tensor(\"args_0:0\", shape=(None, 4), dtype=float32) \n",
      "\n",
      " Tensor(\"strided_slice:0\", shape=(), dtype=int32) \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds_train, ds_train_info = utils.getDataset('train')\n",
    "ds_test, ds_test_info = utils.getDataset('test')\n",
    "ds_eval, ds_eval_info = utils.getDataset('validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import get_file\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = get_file(\n",
    "    \"akidanet_imagenet_224_alpha_50.h5\",\n",
    "    \"http://data.brainchip.com/models/akidanet/akidanet_imagenet_224_alpha_50.h5\",\n",
    "    cache_subdir='models/akidanet_imagenet')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(load_model(model_file)) \n",
    "model.add(Dense(4, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.MeanSquaredError(reduction=\"auto\", name=\"mean_squared_error\"), \n",
    "              metrics=['accuracy'])\n",
    "model.get_layer(index=-1)\n",
    "\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=\"./imagenet_models\",\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=6,\n",
    "    validation_data=ds_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(\n",
    "  ds_eval\n",
    ")\n",
    "\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "model.save(\"models/imagenet_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "model = tf.keras.models.load_model(\"models/imagenet_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 201ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128, 1, 4), dtype=float32, numpy=\n",
       "array([[[0.20383526, 0.3732101 , 0.39107692, 0.41539916]],\n",
       "\n",
       "       [[0.20383525, 0.37321   , 0.3910768 , 0.41539904]],\n",
       "\n",
       "       [[0.20383534, 0.37321037, 0.39107722, 0.41539955]],\n",
       "\n",
       "       [[0.2038353 , 0.3732102 , 0.39107698, 0.41539928]],\n",
       "\n",
       "       [[0.20383534, 0.37321037, 0.39107722, 0.41539955]],\n",
       "\n",
       "       [[0.20383534, 0.37321034, 0.39107716, 0.41539952]],\n",
       "\n",
       "       [[0.20383538, 0.37321055, 0.3910774 , 0.4153998 ]],\n",
       "\n",
       "       [[0.20383525, 0.37321004, 0.3910768 , 0.41539907]],\n",
       "\n",
       "       [[0.20383532, 0.3732103 , 0.39107716, 0.41539946]],\n",
       "\n",
       "       [[0.20383534, 0.37321037, 0.39107722, 0.41539955]],\n",
       "\n",
       "       [[0.2038353 , 0.37321022, 0.39107704, 0.41539934]],\n",
       "\n",
       "       [[0.2038353 , 0.37321028, 0.3910771 , 0.4153994 ]],\n",
       "\n",
       "       [[0.20383535, 0.37321043, 0.39107728, 0.4153996 ]],\n",
       "\n",
       "       [[0.20383531, 0.37321028, 0.3910771 , 0.4153994 ]],\n",
       "\n",
       "       [[0.20383531, 0.37321034, 0.39107716, 0.41539952]],\n",
       "\n",
       "       [[0.20383535, 0.37321046, 0.39107728, 0.41539967]],\n",
       "\n",
       "       [[0.20383528, 0.3732102 , 0.39107698, 0.4153993 ]],\n",
       "\n",
       "       [[0.20383528, 0.3732102 , 0.39107698, 0.4153993 ]],\n",
       "\n",
       "       [[0.20383528, 0.3732101 , 0.39107692, 0.41539913]],\n",
       "\n",
       "       [[0.20383526, 0.37321013, 0.39107692, 0.4153992 ]],\n",
       "\n",
       "       [[0.20383531, 0.37321025, 0.39107704, 0.41539937]],\n",
       "\n",
       "       [[0.2038353 , 0.3732102 , 0.39107698, 0.4153993 ]],\n",
       "\n",
       "       [[0.2038353 , 0.37321022, 0.39107704, 0.41539934]],\n",
       "\n",
       "       [[0.20383532, 0.37321034, 0.39107716, 0.41539952]],\n",
       "\n",
       "       [[0.20383532, 0.37321034, 0.39107716, 0.41539952]],\n",
       "\n",
       "       [[0.2038353 , 0.37321025, 0.39107704, 0.41539934]],\n",
       "\n",
       "       [[0.20383528, 0.3732102 , 0.39107698, 0.4153993 ]],\n",
       "\n",
       "       [[0.20383528, 0.37321022, 0.39107704, 0.4153993 ]],\n",
       "\n",
       "       [[0.20383528, 0.37321016, 0.39107698, 0.41539928]],\n",
       "\n",
       "       [[0.20383526, 0.3732101 , 0.39107692, 0.41539916]],\n",
       "\n",
       "       [[0.2038353 , 0.37321025, 0.39107704, 0.41539937]],\n",
       "\n",
       "       [[0.20383531, 0.37321025, 0.3910771 , 0.41539937]],\n",
       "\n",
       "       [[0.2038353 , 0.37321022, 0.39107704, 0.41539934]],\n",
       "\n",
       "       [[0.20383534, 0.3732104 , 0.39107722, 0.41539958]],\n",
       "\n",
       "       [[0.20383526, 0.37321013, 0.39107692, 0.4153992 ]],\n",
       "\n",
       "       [[0.20383528, 0.3732102 , 0.39107698, 0.4153993 ]],\n",
       "\n",
       "       [[0.20383526, 0.37321013, 0.39107692, 0.41539922]],\n",
       "\n",
       "       [[0.20383538, 0.37321058, 0.39107746, 0.41539982]],\n",
       "\n",
       "       [[0.20383534, 0.3732104 , 0.39107722, 0.41539958]],\n",
       "\n",
       "       [[0.20383535, 0.37321046, 0.39107728, 0.41539967]],\n",
       "\n",
       "       [[0.20383532, 0.3732103 , 0.39107716, 0.41539943]],\n",
       "\n",
       "       [[0.20383526, 0.37321013, 0.39107692, 0.4153992 ]],\n",
       "\n",
       "       [[0.2038353 , 0.3732102 , 0.39107698, 0.41539928]],\n",
       "\n",
       "       [[0.20383532, 0.37321034, 0.39107716, 0.41539952]],\n",
       "\n",
       "       [[0.20383526, 0.37321013, 0.39107692, 0.4153992 ]],\n",
       "\n",
       "       [[0.20383532, 0.3732103 , 0.39107716, 0.41539946]],\n",
       "\n",
       "       [[0.20383528, 0.3732102 , 0.39107698, 0.41539928]],\n",
       "\n",
       "       [[0.20383531, 0.37321028, 0.3910771 , 0.4153994 ]],\n",
       "\n",
       "       [[0.20383531, 0.3732103 , 0.39107716, 0.4153995 ]],\n",
       "\n",
       "       [[0.20383528, 0.37321016, 0.39107698, 0.41539922]],\n",
       "\n",
       "       [[0.20383534, 0.37321037, 0.39107722, 0.41539955]],\n",
       "\n",
       "       [[0.20383528, 0.3732101 , 0.39107692, 0.41539916]],\n",
       "\n",
       "       [[0.20383535, 0.37321043, 0.39107728, 0.41539964]],\n",
       "\n",
       "       [[0.20383526, 0.37321013, 0.39107692, 0.4153992 ]],\n",
       "\n",
       "       [[0.20383537, 0.3732105 , 0.39107734, 0.41539973]],\n",
       "\n",
       "       [[0.20383534, 0.37321037, 0.39107722, 0.41539955]],\n",
       "\n",
       "       [[0.20383531, 0.37321034, 0.39107716, 0.41539952]],\n",
       "\n",
       "       [[0.20383531, 0.37321028, 0.3910771 , 0.4153994 ]],\n",
       "\n",
       "       [[0.20383538, 0.37321055, 0.3910774 , 0.4153998 ]],\n",
       "\n",
       "       [[0.20383531, 0.37321022, 0.39107704, 0.41539934]],\n",
       "\n",
       "       [[0.20383525, 0.37321004, 0.39107686, 0.41539907]],\n",
       "\n",
       "       [[0.20383531, 0.3732103 , 0.39107716, 0.41539943]],\n",
       "\n",
       "       [[0.20383535, 0.37321043, 0.39107728, 0.41539964]],\n",
       "\n",
       "       [[0.20383528, 0.3732102 , 0.39107698, 0.41539928]],\n",
       "\n",
       "       [[0.20383534, 0.37321037, 0.39107722, 0.41539955]],\n",
       "\n",
       "       [[0.20383534, 0.37321037, 0.39107722, 0.41539955]],\n",
       "\n",
       "       [[0.20383534, 0.37321034, 0.39107716, 0.41539952]],\n",
       "\n",
       "       [[0.20383532, 0.37321034, 0.39107716, 0.41539952]],\n",
       "\n",
       "       [[0.20383531, 0.37321028, 0.3910771 , 0.41539943]],\n",
       "\n",
       "       [[0.20383531, 0.37321028, 0.3910771 , 0.4153994 ]],\n",
       "\n",
       "       [[0.20383526, 0.37321013, 0.39107692, 0.4153992 ]],\n",
       "\n",
       "       [[0.20383532, 0.3732103 , 0.39107716, 0.41539946]],\n",
       "\n",
       "       [[0.20383537, 0.3732105 , 0.39107734, 0.41539967]],\n",
       "\n",
       "       [[0.20383532, 0.3732103 , 0.39107716, 0.41539943]],\n",
       "\n",
       "       [[0.20383531, 0.3732103 , 0.39107716, 0.4153995 ]],\n",
       "\n",
       "       [[0.2038353 , 0.3732102 , 0.39107698, 0.4153993 ]],\n",
       "\n",
       "       [[0.20383528, 0.37321016, 0.39107698, 0.41539925]],\n",
       "\n",
       "       [[0.20383535, 0.37321043, 0.39107728, 0.41539964]],\n",
       "\n",
       "       [[0.20383532, 0.3732103 , 0.39107716, 0.41539943]],\n",
       "\n",
       "       [[0.20383532, 0.37321034, 0.39107716, 0.41539952]],\n",
       "\n",
       "       [[0.20383531, 0.37321028, 0.3910771 , 0.4153994 ]],\n",
       "\n",
       "       [[0.2038353 , 0.37321025, 0.3910771 , 0.4153994 ]],\n",
       "\n",
       "       [[0.20383528, 0.3732102 , 0.39107698, 0.41539928]],\n",
       "\n",
       "       [[0.2038353 , 0.37321028, 0.3910771 , 0.4153994 ]],\n",
       "\n",
       "       [[0.2038353 , 0.37321022, 0.39107704, 0.41539934]],\n",
       "\n",
       "       [[0.20383532, 0.3732103 , 0.39107716, 0.41539946]],\n",
       "\n",
       "       [[0.20383531, 0.3732103 , 0.39107716, 0.41539943]],\n",
       "\n",
       "       [[0.20383528, 0.3732102 , 0.39107698, 0.4153993 ]],\n",
       "\n",
       "       [[0.20383537, 0.3732105 , 0.39107734, 0.4153997 ]],\n",
       "\n",
       "       [[0.20383525, 0.37321004, 0.39107686, 0.41539907]],\n",
       "\n",
       "       [[0.20383531, 0.37321022, 0.39107704, 0.41539934]],\n",
       "\n",
       "       [[0.20383532, 0.37321034, 0.39107716, 0.41539952]],\n",
       "\n",
       "       [[0.2038353 , 0.37321025, 0.39107704, 0.41539937]],\n",
       "\n",
       "       [[0.20383531, 0.37321028, 0.3910771 , 0.4153994 ]],\n",
       "\n",
       "       [[0.20383531, 0.37321028, 0.3910771 , 0.4153994 ]],\n",
       "\n",
       "       [[0.20383532, 0.3732103 , 0.39107716, 0.41539943]],\n",
       "\n",
       "       [[0.20383534, 0.37321037, 0.39107722, 0.41539952]],\n",
       "\n",
       "       [[0.20383532, 0.37321034, 0.39107716, 0.41539952]],\n",
       "\n",
       "       [[0.2038353 , 0.37321025, 0.39107704, 0.41539937]],\n",
       "\n",
       "       [[0.20383534, 0.37321037, 0.39107722, 0.41539955]],\n",
       "\n",
       "       [[0.20383532, 0.37321034, 0.39107716, 0.41539946]],\n",
       "\n",
       "       [[0.2038353 , 0.37321028, 0.3910771 , 0.4153994 ]],\n",
       "\n",
       "       [[0.20383532, 0.37321034, 0.39107716, 0.4153995 ]],\n",
       "\n",
       "       [[0.20383535, 0.37321043, 0.39107728, 0.4153996 ]],\n",
       "\n",
       "       [[0.20383535, 0.37321043, 0.39107728, 0.41539964]],\n",
       "\n",
       "       [[0.2038353 , 0.37321025, 0.39107704, 0.41539934]],\n",
       "\n",
       "       [[0.2038353 , 0.37321025, 0.3910771 , 0.41539937]],\n",
       "\n",
       "       [[0.20383532, 0.37321034, 0.39107716, 0.41539952]],\n",
       "\n",
       "       [[0.20383534, 0.37321037, 0.39107722, 0.41539955]],\n",
       "\n",
       "       [[0.20383546, 0.37321088, 0.39107776, 0.4154002 ]],\n",
       "\n",
       "       [[0.20383528, 0.3732102 , 0.39107698, 0.41539928]],\n",
       "\n",
       "       [[0.20383532, 0.37321037, 0.39107722, 0.41539958]],\n",
       "\n",
       "       [[0.20383531, 0.37321022, 0.39107704, 0.41539934]],\n",
       "\n",
       "       [[0.20383532, 0.37321034, 0.39107716, 0.41539946]],\n",
       "\n",
       "       [[0.20383534, 0.37321043, 0.39107728, 0.4153996 ]],\n",
       "\n",
       "       [[0.20383528, 0.37321022, 0.39107704, 0.4153993 ]],\n",
       "\n",
       "       [[0.20383532, 0.37321034, 0.39107716, 0.41539952]],\n",
       "\n",
       "       [[0.20383522, 0.37321   , 0.3910768 , 0.41539904]],\n",
       "\n",
       "       [[0.2038353 , 0.3732102 , 0.39107698, 0.4153993 ]],\n",
       "\n",
       "       [[0.20383534, 0.37321043, 0.39107728, 0.4153996 ]],\n",
       "\n",
       "       [[0.2038353 , 0.37321022, 0.39107704, 0.41539934]],\n",
       "\n",
       "       [[0.20383532, 0.37321034, 0.39107716, 0.41539952]],\n",
       "\n",
       "       [[0.20383541, 0.37321073, 0.39107764, 0.41540003]],\n",
       "\n",
       "       [[0.20383538, 0.37321058, 0.39107746, 0.41539982]],\n",
       "\n",
       "       [[0.20383535, 0.37321043, 0.39107728, 0.41539964]],\n",
       "\n",
       "       [[0.20383532, 0.37321037, 0.39107722, 0.41539955]],\n",
       "\n",
       "       [[0.20383531, 0.37321028, 0.3910771 , 0.4153994 ]],\n",
       "\n",
       "       [[0.20383532, 0.37321034, 0.39107716, 0.41539952]]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128, 1, 4), dtype=float32, numpy=\n",
       "array([[[0.14975041, 0.4375    , 0.33943427, 0.5175781 ]],\n",
       "\n",
       "       [[0.23096447, 0.32617188, 0.7385787 , 0.6191406 ]],\n",
       "\n",
       "       [[0.24745269, 0.39648438, 0.41339156, 0.48046875]],\n",
       "\n",
       "       [[0.6734993 , 0.47460938, 0.74963397, 0.5625    ]],\n",
       "\n",
       "       [[0.3375    , 0.40039062, 0.384375  , 0.43945312]],\n",
       "\n",
       "       [[0.07377049, 0.28710938, 0.9508197 , 0.7324219 ]],\n",
       "\n",
       "       [[0.4513889 , 0.15820312, 0.8298611 , 0.46875   ]],\n",
       "\n",
       "       [[0.56764704, 0.27929688, 0.7470588 , 0.34375   ]],\n",
       "\n",
       "       [[0.09773463, 0.40429688, 0.26796117, 0.5810547 ]],\n",
       "\n",
       "       [[0.24633431, 0.390625  , 0.47800586, 0.50390625]],\n",
       "\n",
       "       [[0.18122555, 0.20214844, 0.63428944, 0.65234375]],\n",
       "\n",
       "       [[0.17774668, 0.26660156, 0.63680893, 0.7519531 ]],\n",
       "\n",
       "       [[0.00387597, 0.6308594 , 0.14664082, 0.79296875]],\n",
       "\n",
       "       [[0.05647059, 0.57128906, 0.26764706, 0.7402344 ]],\n",
       "\n",
       "       [[0.5625    , 0.7421875 , 0.67663044, 0.8203125 ]],\n",
       "\n",
       "       [[0.09375   , 0.30859375, 0.31835938, 0.46875   ]],\n",
       "\n",
       "       [[0.06229721, 0.26171875, 0.40038934, 0.5966797 ]],\n",
       "\n",
       "       [[0.27818447, 0.5078125 , 0.4275256 , 0.578125  ]],\n",
       "\n",
       "       [[0.12737921, 0.4951172 , 0.20058565, 0.53808594]],\n",
       "\n",
       "       [[0.0722973 , 0.5058594 , 0.17027026, 0.5966797 ]],\n",
       "\n",
       "       [[0.02928258, 0.44140625, 0.2137628 , 0.53125   ]],\n",
       "\n",
       "       [[0.06770834, 0.        , 0.9244792 , 0.34570312]],\n",
       "\n",
       "       [[0.19097222, 0.24609375, 0.7395833 , 0.47070312]],\n",
       "\n",
       "       [[0.19912152, 0.25976562, 0.37481698, 0.34375   ]],\n",
       "\n",
       "       [[0.19534884, 0.3203125 , 0.7875969 , 0.6503906 ]],\n",
       "\n",
       "       [[0.27383015, 0.38085938, 0.50606585, 0.5136719 ]],\n",
       "\n",
       "       [[0.34324324, 0.8017578 , 0.40135136, 0.8300781 ]],\n",
       "\n",
       "       [[0.17350158, 0.40820312, 0.59305996, 0.57421875]],\n",
       "\n",
       "       [[0.17983872, 0.13964844, 0.5       , 0.50097656]],\n",
       "\n",
       "       [[0.17604712, 0.3671875 , 0.45942408, 0.65625   ]],\n",
       "\n",
       "       [[0.19503546, 0.20410156, 0.6755319 , 0.5439453 ]],\n",
       "\n",
       "       [[0.12480499, 0.5644531 , 0.4929797 , 0.7265625 ]],\n",
       "\n",
       "       [[0.33854166, 0.05664062, 0.38020834, 0.07910156]],\n",
       "\n",
       "       [[0.11140583, 0.38085938, 0.56233424, 0.60546875]],\n",
       "\n",
       "       [[0.01041667, 0.5917969 , 0.8784722 , 0.94921875]],\n",
       "\n",
       "       [[0.08002303, 0.4501953 , 0.1871042 , 0.5859375 ]],\n",
       "\n",
       "       [[0.23888889, 0.3955078 , 0.6333333 , 0.7109375 ]],\n",
       "\n",
       "       [[0.02206897, 0.70703125, 0.15172414, 0.7792969 ]],\n",
       "\n",
       "       [[0.12445095, 0.25878906, 0.20644216, 0.3046875 ]],\n",
       "\n",
       "       [[0.10351562, 0.33691406, 0.29296875, 0.5654297 ]],\n",
       "\n",
       "       [[0.07979071, 0.32910156, 0.28057554, 0.55078125]],\n",
       "\n",
       "       [[0.22934648, 0.47753906, 0.297164  , 0.5253906 ]],\n",
       "\n",
       "       [[0.1438515 , 0.5136719 , 0.6102088 , 0.8417969 ]],\n",
       "\n",
       "       [[0.16180371, 0.40429688, 0.48806366, 0.5703125 ]],\n",
       "\n",
       "       [[0.23658536, 0.5703125 , 0.3902439 , 0.6386719 ]],\n",
       "\n",
       "       [[0.10182767, 0.40039062, 0.4007833 , 0.7363281 ]],\n",
       "\n",
       "       [[0.07634629, 0.2734375 , 0.35923654, 0.5722656 ]],\n",
       "\n",
       "       [[0.390625  , 0.46289062, 0.51785713, 0.54296875]],\n",
       "\n",
       "       [[0.22613803, 0.5761719 , 0.57856095, 0.7519531 ]],\n",
       "\n",
       "       [[0.00821168, 0.17285156, 0.23266423, 0.35839844]],\n",
       "\n",
       "       [[0.09960938, 0.3251953 , 0.32617188, 0.5683594 ]],\n",
       "\n",
       "       [[0.06445312, 0.3564453 , 0.50130206, 0.7949219 ]],\n",
       "\n",
       "       [[0.        , 0.21875   , 0.33969465, 0.33203125]],\n",
       "\n",
       "       [[0.08809684, 0.33398438, 0.48419636, 0.73339844]],\n",
       "\n",
       "       [[0.10351562, 0.39257812, 0.296875  , 0.57128906]],\n",
       "\n",
       "       [[0.31578946, 0.39257812, 0.39603105, 0.45898438]],\n",
       "\n",
       "       [[0.15395096, 0.41992188, 0.22752044, 0.453125  ]],\n",
       "\n",
       "       [[0.3090278 , 0.25      , 0.4513889 , 0.30273438]],\n",
       "\n",
       "       [[0.08680555, 0.26757812, 0.9965278 , 0.6386719 ]],\n",
       "\n",
       "       [[0.18155198, 0.43945312, 0.27818447, 0.4921875 ]],\n",
       "\n",
       "       [[0.08463541, 0.37890625, 0.1328125 , 0.41601562]],\n",
       "\n",
       "       [[0.03713528, 0.0625    , 0.9124668 , 0.90234375]],\n",
       "\n",
       "       [[0.37760416, 0.7363281 , 0.49479166, 0.8105469 ]],\n",
       "\n",
       "       [[0.14059754, 0.28027344, 0.53690684, 0.6386719 ]],\n",
       "\n",
       "       [[0.17569546, 0.44726562, 0.32503662, 0.5234375 ]],\n",
       "\n",
       "       [[0.1734104 , 0.30859375, 0.61271673, 0.69921875]],\n",
       "\n",
       "       [[0.17773438, 0.70703125, 0.296875  , 0.7792969 ]],\n",
       "\n",
       "       [[0.10947368, 0.39648438, 0.22245614, 0.5107422 ]],\n",
       "\n",
       "       [[0.104     , 0.5488281 , 0.22666667, 0.6152344 ]],\n",
       "\n",
       "       [[0.1482808 , 0.3720703 , 0.40186247, 0.6035156 ]],\n",
       "\n",
       "       [[0.2890625 , 0.29882812, 0.48632812, 0.44335938]],\n",
       "\n",
       "       [[0.11132941, 0.18847656, 0.22658809, 0.3251953 ]],\n",
       "\n",
       "       [[0.14930555, 0.45898438, 0.3576389 , 0.54296875]],\n",
       "\n",
       "       [[0.35171387, 0.7734375 , 0.64977646, 0.8671875 ]],\n",
       "\n",
       "       [[0.05490483, 0.4140625 , 0.1566618 , 0.5048828 ]],\n",
       "\n",
       "       [[0.32226562, 0.27539062, 0.49414062, 0.4658203 ]],\n",
       "\n",
       "       [[0.34765625, 0.50390625, 0.3984375 , 0.55859375]],\n",
       "\n",
       "       [[0.04147466, 0.44726562, 0.1359447 , 0.4794922 ]],\n",
       "\n",
       "       [[0.3338214 , 0.37304688, 0.70863837, 0.5839844 ]],\n",
       "\n",
       "       [[0.154047  , 0.25976562, 0.46475196, 0.38671875]],\n",
       "\n",
       "       [[0.21548821, 0.80078125, 0.37710437, 0.8730469 ]],\n",
       "\n",
       "       [[0.15812592, 0.3623047 , 0.28330892, 0.5       ]],\n",
       "\n",
       "       [[0.3090278 , 0.31640625, 0.4722222 , 0.484375  ]],\n",
       "\n",
       "       [[0.29427084, 0.31445312, 0.390625  , 0.38671875]],\n",
       "\n",
       "       [[0.11458334, 0.6425781 , 0.40104166, 0.78515625]],\n",
       "\n",
       "       [[0.24011713, 0.5410156 , 0.59736454, 0.7949219 ]],\n",
       "\n",
       "       [[0.3671875 , 0.9082031 , 0.4765625 , 0.9667969 ]],\n",
       "\n",
       "       [[0.09480122, 0.38867188, 0.48318043, 0.5703125 ]],\n",
       "\n",
       "       [[0.14641288, 0.6699219 , 0.25475842, 0.72265625]],\n",
       "\n",
       "       [[0.07977992, 0.44335938, 0.24140303, 0.62597656]],\n",
       "\n",
       "       [[0.27312776, 0.16992188, 0.46696034, 0.27148438]],\n",
       "\n",
       "       [[0.03125   , 0.34570312, 0.15234375, 0.4892578 ]],\n",
       "\n",
       "       [[0.22659667, 0.19433594, 0.93088365, 0.7451172 ]],\n",
       "\n",
       "       [[0.1933488 , 0.26367188, 0.5676721 , 0.7685547 ]],\n",
       "\n",
       "       [[0.11488863, 0.21484375, 0.42438453, 0.40039062]],\n",
       "\n",
       "       [[0.0546875 , 0.7519531 , 0.2109375 , 0.8339844 ]],\n",
       "\n",
       "       [[0.05155747, 0.203125  , 0.99677765, 0.87890625]],\n",
       "\n",
       "       [[0.14692557, 0.22167969, 0.5398058 , 0.58496094]],\n",
       "\n",
       "       [[0.17196625, 0.296875  , 0.5567813 , 0.71191406]],\n",
       "\n",
       "       [[0.05490483, 0.453125  , 0.18374817, 0.5888672 ]],\n",
       "\n",
       "       [[0.03082192, 0.49121094, 0.14726028, 0.5332031 ]],\n",
       "\n",
       "       [[0.10758263, 0.4267578 , 0.34348673, 0.66503906]],\n",
       "\n",
       "       [[0.21637426, 0.45410156, 0.30604288, 0.54785156]],\n",
       "\n",
       "       [[0.05      , 0.01171875, 0.46470588, 0.23046875]],\n",
       "\n",
       "       [[0.3125    , 0.20703125, 0.5208333 , 0.30273438]],\n",
       "\n",
       "       [[0.11924822, 0.48535156, 0.20544393, 0.58203125]],\n",
       "\n",
       "       [[0.06472262, 0.359375  , 0.26386914, 0.5761719 ]],\n",
       "\n",
       "       [[0.17317073, 0.44140625, 0.36097562, 0.5625    ]],\n",
       "\n",
       "       [[0.06657019, 0.64453125, 0.17945008, 0.7011719 ]],\n",
       "\n",
       "       [[0.09203655, 0.46484375, 0.18015666, 0.5761719 ]],\n",
       "\n",
       "       [[0.13328776, 0.33007812, 0.5167464 , 0.69628906]],\n",
       "\n",
       "       [[0.21081577, 0.38867188, 0.42163154, 0.57128906]],\n",
       "\n",
       "       [[0.49479166, 0.38378906, 0.7369792 , 0.6035156 ]],\n",
       "\n",
       "       [[0.13109978, 0.32714844, 0.4828842 , 0.6435547 ]],\n",
       "\n",
       "       [[0.07421875, 0.41992188, 0.25      , 0.55859375]],\n",
       "\n",
       "       [[0.29073942, 0.21972656, 0.7724336 , 0.71875   ]],\n",
       "\n",
       "       [[0.34101382, 0.40625   , 0.41474655, 0.46679688]],\n",
       "\n",
       "       [[0.19512194, 0.609375  , 0.3707317 , 0.71484375]],\n",
       "\n",
       "       [[0.3762811 , 0.48339844, 0.47437775, 0.5332031 ]],\n",
       "\n",
       "       [[0.08441558, 0.3798828 , 0.27207792, 0.57714844]],\n",
       "\n",
       "       [[0.15789473, 0.5390625 , 0.38995215, 0.6777344 ]],\n",
       "\n",
       "       [[0.29568106, 0.28515625, 0.38870433, 0.38085938]],\n",
       "\n",
       "       [[0.16908212, 0.7109375 , 0.3043478 , 0.765625  ]],\n",
       "\n",
       "       [[0.00920245, 0.21484375, 1.        , 0.77734375]],\n",
       "\n",
       "       [[0.10769231, 0.24023438, 0.41538462, 0.49414062]],\n",
       "\n",
       "       [[0.21805006, 0.3701172 , 0.5046113 , 0.7402344 ]],\n",
       "\n",
       "       [[0.13896103, 0.35253906, 0.42857143, 0.6904297 ]],\n",
       "\n",
       "       [[0.41778976, 0.4921875 , 0.5714286 , 0.6113281 ]]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for ele in ds_eval.take(1):\n",
    "\n",
    "  predictions = tf.convert_to_tensor([np.array([bbox]) for bbox in model.predict(ele[0])])\n",
    "\n",
    "  display(predictions)\n",
    "  display(ele[1])\n",
    "\n",
    "  images = tf.image.draw_bounding_boxes(\n",
    "    ele[0], ele[1], [(0, 0, 255) for _ in range(len(ele[0]))], name=None\n",
    "    )\n",
    "  \n",
    "  images = tf.image.draw_bounding_boxes(\n",
    "    images, predictions, [(0, 255, 0) for _ in range(len(images))], name=None\n",
    "    )\n",
    "\n",
    "  for image in images:\n",
    "\n",
    "    image = (np.array(image)*255).astype(np.uint8)\n",
    "\n",
    "    from PIL import Image\n",
    "    im = Image.fromarray(image)\n",
    "    im.save(\"tensor.jpeg\")\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for box in [bbox, prediction]:\n",
    "\n",
    "  x = box[0]\n",
    "  y = box[1]\n",
    "  xx = box[2]\n",
    "  yy = box[3]\n",
    "\n",
    "  print(\"x \", x, \"y \", y, \"xx \", xx, \"yy\", yy)\n",
    "\n",
    "  cv2.rectangle(image, (x, y), (xx, yy), (0, 0, 255), 2)\n",
    "  print(\"x,y,w,h:\",x,y,xx,yy)\n",
    "  \n",
    "# save resulting image\n",
    "cv2.imwrite('example.jpg', image)      \n",
    "\n",
    "# show thresh and result    \n",
    "cv2.imshow(\"bounding_box\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "studienarbeit_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5af87179686f79906606ada0849899045151fdfcd8253dc4e17141c7c7556e1d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
