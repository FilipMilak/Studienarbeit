{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "21"
    }
   },
   "outputs": [],
   "source": [
    "# model_name = \"yolo\"\n",
    "# model_name = \"imagenet\"\n",
    "# model_name = \"cnn\"\n",
    "# model_name = \"wider\"\n",
    "model_name = \"vgg\"\n",
    "# model_name = \"vggface\"\n",
    "#model_name = \"vggface_resnet\"\n",
    "#model_name = \"vggface_senet\"\n",
    "#model_name = \"vggface\"\n",
    "use_gray = False\n",
    "only_one = False\n",
    "isTrainable = False\n",
    "batch_size = 32\n",
    "learning_rate = 5e-5\n",
    "epochs = 80\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "image_shape = (224,224, 1 if use_gray else 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "#%env CUDA_VISIBLE_DEVICES=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-26 07:13:47.602353: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow.image import resize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import albumentations as alb\n",
    "\n",
    "augmentor = alb.Compose([#alb.RandomCrop(width=150, height=150), \n",
    "                        alb.HorizontalFlip(p=0.5), \n",
    "                        alb.RandomBrightnessContrast(p=0.2),\n",
    "                        alb.RandomGamma(p=0.2), \n",
    "                        alb.RGBShift(p=0.2), \n",
    "                        alb.VerticalFlip(p=0.5)], \n",
    "                      bbox_params=alb.BboxParams(format='albumentations', \n",
    "                                                 label_fields=['class_labels'],\n",
    "                                                 min_area=0.1))\n",
    "\n",
    "\n",
    "def aug_fn(image, bbox, img_size):\n",
    "  \n",
    "    \n",
    "    try:\n",
    "      aug_data = augmentor(image = image, bboxes = bbox, class_labels=['face'])\n",
    "    except Exception as e:\n",
    "      display(f\"Bbox makes problems: {bbox} \\n{e}\")\n",
    "      aug_data = augmentor(image = image, bboxes = tf.convert_to_tensor([[0.,0.,1e-2,1e-2]]), class_labels=['face'])\n",
    "    aug_img = aug_data[\"image\"]\n",
    "    aug_img = tf.cast(aug_img/255.0, tf.float32)\n",
    "    aug_img = tf.image.resize(aug_img, size=[img_size, img_size])\n",
    "\n",
    "    aug_bbox = aug_data[\"bboxes\"]\n",
    "    aug_bbox = tf.cast(aug_bbox, tf.float32)\n",
    "    \n",
    "    #display(aug_bbox)\n",
    "\n",
    "    return aug_img, aug_bbox\n",
    "\n",
    "def process_data(image, bbox, img_size):\n",
    "  \n",
    "    image, bbox = tf.numpy_function(func=aug_fn, inp=[image, bbox, img_size], Tout=(tf.float32, tf.float32))\n",
    "\n",
    "    return image, bbox #tf.convert_to_tensor([bbox, [is_bbox]]) \n",
    "\n",
    "def aug_fn_test(aug_img,  img_size):\n",
    "    \n",
    "    aug_img = tf.cast(aug_img/255.0, tf.float32)\n",
    "    aug_img = tf.image.resize(aug_img, size=[img_size, img_size])\n",
    "\n",
    "    return aug_img\n",
    "\n",
    "def process_data_test(image, img_size):\n",
    "\n",
    "    image = tf.numpy_function(func=aug_fn_test, inp=[image, img_size], Tout=tf.float32)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def set_shapes(img, bbox=None, img_shape=(224,224,3)):\n",
    "    \n",
    "    img = tf.reshape(img, img_shape)    \n",
    "    \n",
    "    if bbox is not None:\n",
    "      bbox = tf.reshape(bbox,[-1,4])\n",
    "      return img, bbox\n",
    "    else: \n",
    "      return img\n",
    "    \n",
    "\n",
    "  \n",
    "def getDataset(name: str, batch_size: int = 32, image_shape: tuple[int, int, int] = (224, 224, 3)) -> tuple[tf.data.Dataset, None]:\n",
    "  \n",
    "  ds, ds_info = tfds.load('wider_face', split=name, shuffle_files=True, with_info=True, data_dir=\"/scratch/fs2/Fimilak/tensorflow_datasets/\")\n",
    "\n",
    "  if name != \"test\":\n",
    "    \n",
    "    #ds = ds.map(lambda x: [x[\"image\"], tf.convert_to_tensor([[0.,0.,1e-2,1e-2]]) if x[\"faces\"][\"bbox\"].shape[0] is None else x[\"faces\"][\"bbox\"]],\n",
    "    \n",
    "    #display(f\"BEFORE LENGTH OF {name} is {len(list(ds))}\")\n",
    "    \n",
    "    #ds.map(lambda x,y: [x, y] if display(y.shape) is None else [x, y])\n",
    "        \n",
    "    ds_1 = ds.filter(lambda x: tf.shape(x[\"faces\"][\"bbox\"])[0] == 1)\n",
    "    ds_1 = ds_1.map(lambda x: [x[\"image\"], x[\"faces\"][\"bbox\"]])\n",
    "   \n",
    "    #for y, x in tfds.as_numpy(ds_1.take(2)):\n",
    "    ##  \n",
    "    #  display(x.shape)\n",
    "    #  display(x)\n",
    "    \n",
    "    ds_0 = ds.filter(lambda x: tf.shape(x[\"faces\"][\"bbox\"])[0] == 0)\n",
    "    ds_0 = ds_0.map(lambda x: [x[\"image\"], tf.convert_to_tensor([[0.,0.,1e-2,1e-2]])])\n",
    "    \n",
    "    ds = ds_0.concatenate(ds_1)\n",
    "    \n",
    "    ds = ds.map(lambda x, y: process_data(x, y, img_size=image_shape[0]),\n",
    "                      num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    ds = ds.map(set_shapes,\n",
    "                      num_parallel_calls=tf.data.AUTOTUNE).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "  else:\n",
    "    ds = ds.map(lambda x: process_data_test(x[\"image\"], img_size=image_shape[0]),\n",
    "                      num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
    "    ds = ds.map(set_shapes,\n",
    "                      num_parallel_calls=tf.data.AUTOTUNE).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "ds_train = getDataset('train', batch_size=batch_size, image_shape=image_shape)\n",
    "ds_eval = getDataset('validation', batch_size=batch_size, image_shape=image_shape)\n",
    "ds_test = getDataset('test', batch_size=batch_size, image_shape=image_shape)\n",
    "\n",
    "for _ in range(60):\n",
    "    ds_train = ds_train.concatenate(getDataset('train', batch_size=batch_size, image_shape=image_shape))\n",
    "    ds_eval = ds_eval.concatenate(getDataset('validation', batch_size=batch_size, image_shape=image_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(len(list(ds_train)))\n",
    "#display(len(list(ds_eval)))\n",
    "#display(len(list(ds_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "#from akida_models import yolo_base, yolo_widerface_pretrained\n",
    "from tensorflow.keras.utils import get_file\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, ReLU, BatchNormalization, Input, GlobalMaxPooling2D, Dropout\n",
    "from tensorflow.keras import Sequential\n",
    "#import keras_vggface\n",
    "#from keras_vggface.vggface import VGGFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVGGCustom(model, isTrainable: bool = True):\n",
    "    \n",
    "    model.trainable = isTrainable\n",
    "    #last_layer = model.get_layer('avg_pool').output\n",
    "    \n",
    "    inputs = tf.keras.Input(shape=(image_shape))\n",
    "    \n",
    "    x = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip('horizontal'),\n",
    "    tf.keras.layers.RandomRotation(0.2),\n",
    "    ])(inputs)\n",
    "    \n",
    "    x = model(x)\n",
    "    \n",
    "    x = Flatten(name='flatten')(x)\n",
    "    \n",
    "    x = Dropout(.2)(x)\n",
    "    \n",
    "    out = Dense(4, name='regressor')(x)\n",
    "    \n",
    "    return Model(inputs, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "if not \"vgg\" in model_name:\n",
    "\n",
    "    model : Sequential = Sequential()\n",
    "\n",
    "    if(model_name == \"yolo\"):\n",
    "        yolo_model = yolo_base()\n",
    "        \n",
    "        print(yolo_model.summary())\n",
    "        \n",
    "        model.add(yolo_model)\n",
    "        \n",
    "    elif model_name == \"wider\":\n",
    "        \n",
    "        model, anchors = yolo_widerface_pretrained()\n",
    "        \n",
    "        print(model.predict(ds_eval))\n",
    "        \n",
    "        #utils.predict(model=model, model_name=model_name, ds)\n",
    "        \n",
    "    elif(model_name == \"imagenet\"):\n",
    "        \n",
    "        model_file = get_file(\n",
    "            \"akidanet_imagenet_224_alpha_50.h5\",\n",
    "            \"http://data.brainchip.com/models/akidanet/akidanet_imagenet_224_alpha_50.h5\",\n",
    "            cache_subdir='models/akidanet_imagenet')\n",
    "        model.add(load_model(model_file))\n",
    "\n",
    "    elif(model_name == \"cnn\"):\n",
    "        \n",
    "        input_shapes = [\n",
    "        image_shape,\n",
    "        (224,224,16),\n",
    "        (112,112,32),\n",
    "        (56,56,64),\n",
    "        (28,28,128),\n",
    "        (14,14,1024),\n",
    "        (14,14,512),\n",
    "        (7,7,256),\n",
    "        (7,7,128),\n",
    "        (7,7,64),\n",
    "        (7,7,32),\n",
    "        (4,)]\n",
    "\n",
    "        for input_shape in input_shapes:\n",
    "        \n",
    "            model.add(Conv2D(2,7, input_shape=input_shape)) \n",
    "            model.add(BatchNormalization(input_shape=input_shape)) \n",
    "            model.add(ReLU(input_shape=input_shape))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "elif model_name == \"vgg\":\n",
    "    input_layer = Input(shape=image_shape)\n",
    "    \n",
    "    vgg = VGG16(include_top=False)\n",
    "    \n",
    "    if not isTrainable:\n",
    "        for layer in vgg.layers:\n",
    "            layer.trainable = False\n",
    "            \n",
    "    vgg = vgg(input_layer)\n",
    "\n",
    "    # Classification Model  \n",
    "    f1 = GlobalMaxPooling2D()(vgg)\n",
    "    class1 = Dense(2048, activation='relu')(f1)\n",
    "    class2 = Dense(1, activation='sigmoid')(class1)\n",
    "    \n",
    "    # Bounding box model\n",
    "    f2 = GlobalMaxPooling2D()(vgg)\n",
    "    regress1 = Dense(2048, activation='relu')(f2)\n",
    "    regress2 = Dense(4, activation='sigmoid')(regress1)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=regress2)\n",
    "    #model = Model(inputs=input_layer, outputs=[regress2, class2])\n",
    "    \n",
    "elif model_name == \"vggface\":  \n",
    "    model = getVGGCustom(VGGFace(model='vgg16', include_top=False, input_shape = image_shape), isTrainable=isTrainable)\n",
    "elif model_name == \"vggface_resnet\":  \n",
    "    model = getVGGCustom(VGGFace(model='resnet50', include_top=False, input_shape = image_shape), isTrainable=isTrainable)\n",
    "elif model_name == \"vggface_senet\" :  \n",
    "    model = getVGGCustom(VGGFace(model='senet50', include_top=False, input_shape = image_shape), isTrainable=isTrainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def localization_loss(y_true, yhat):  \n",
    "    display(y_true)\n",
    "    display(yhat)\n",
    "    delta_coord = tf.reduce_sum(tf.square(y_true[...,:2] - yhat[...,:2]))\n",
    "                  \n",
    "    h_true = y_true[...,3] - y_true[...,1] \n",
    "    w_true = y_true[...,2] - y_true[...,0] \n",
    "\n",
    "    h_pred = yhat[...,3] - yhat[...,1] \n",
    "    w_pred = yhat[...,2] - yhat[...,0] \n",
    "    \n",
    "    delta_size = tf.reduce_sum(tf.square(w_true - w_pred) + tf.square(h_true-h_pred))\n",
    "    \n",
    "    return delta_coord + delta_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "              loss=localization_loss, #MeanSquaredError(),#\n",
    "              metrics=['accuracy'])#[tf.keras.metrics.MeanIoU(num_classes=1)])\n",
    "\n",
    "\n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1037/Unknown - 560s 532ms/step - loss: 147.0355 - accuracy: 0.5178"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=ds_train,\n",
    "    epochs=epochs,\n",
    "    validation_data=ds_eval,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpathlib\u001b[39;00m \u001b[39mimport\u001b[39;00m Path\n\u001b[0;32m----> 3\u001b[0m results \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(\n\u001b[1;32m      4\u001b[0m   ds_eval\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtest loss, test acc:\u001b[39m\u001b[39m\"\u001b[39m, results)\n\u001b[1;32m      9\u001b[0m Path(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodels/\u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m_model\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mmkdir(parents\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "results = model.evaluate(\n",
    "  ds_eval\n",
    ")\n",
    "\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "Path(f\"models/{model_name}_model\").mkdir(parents=True, exist_ok=True) \n",
    "model.save(f\"models/{model_name}_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#try:\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mload_model(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmodels/\u001b[39;49m\u001b[39m{\u001b[39;49;00mmodel_name\u001b[39m}\u001b[39;49;00m\u001b[39m_model\u001b[39;49m\u001b[39m\"\u001b[39;49m, custom_objects\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mlocalization_loss\u001b[39;49m\u001b[39m'\u001b[39;49m : utils\u001b[39m.\u001b[39;49mlocalization_loss})\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/saving/save.py:212\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(filepath, six\u001b[39m.\u001b[39mstring_types):\n\u001b[1;32m    211\u001b[0m       loader_impl\u001b[39m.\u001b[39mparse_saved_model(filepath)\n\u001b[0;32m--> 212\u001b[0m       \u001b[39mreturn\u001b[39;00m saved_model_load\u001b[39m.\u001b[39;49mload(filepath, \u001b[39mcompile\u001b[39;49m, options)\n\u001b[1;32m    214\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\n\u001b[1;32m    215\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mUnable to load model. Filepath is not an hdf5 file (or h5py is not \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    216\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mavailable) or SavedModel.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/saving/saved_model/load.py:138\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, compile, options)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39m# Recreate layers and metrics using the info stored in the metadata.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m keras_loader \u001b[39m=\u001b[39m KerasObjectLoader(metadata, object_graph_def)\n\u001b[0;32m--> 138\u001b[0m keras_loader\u001b[39m.\u001b[39;49mload_layers(\u001b[39mcompile\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mcompile\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m \u001b[39m# Generate a dictionary of all loaded nodes.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m nodes_to_load \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mroot\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mNone\u001b[39;00m}\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/saving/saved_model/load.py:374\u001b[0m, in \u001b[0;36mKerasObjectLoader.load_layers\u001b[0;34m(self, compile)\u001b[0m\n\u001b[1;32m    371\u001b[0m     metric_list\u001b[39m.\u001b[39mappend(node_metadata)\n\u001b[1;32m    372\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m--> 374\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloaded_nodes[node_metadata\u001b[39m.\u001b[39mnode_id] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_layer(\n\u001b[1;32m    375\u001b[0m       node_metadata\u001b[39m.\u001b[39;49mnode_id, node_metadata\u001b[39m.\u001b[39;49midentifier,\n\u001b[1;32m    376\u001b[0m       node_metadata\u001b[39m.\u001b[39;49mmetadata)\n\u001b[1;32m    378\u001b[0m \u001b[39mfor\u001b[39;00m node_metadata \u001b[39min\u001b[39;00m metric_list:\n\u001b[1;32m    379\u001b[0m   \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/saving/saved_model/load.py:397\u001b[0m, in \u001b[0;36mKerasObjectLoader._load_layer\u001b[0;34m(self, node_id, identifier, metadata)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_load_layer\u001b[39m(\u001b[39mself\u001b[39m, node_id, identifier, metadata):\n\u001b[1;32m    396\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Load a single layer from a SavedUserObject proto.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 397\u001b[0m   metadata \u001b[39m=\u001b[39m json_utils\u001b[39m.\u001b[39;49mdecode(metadata)\n\u001b[1;32m    399\u001b[0m   \u001b[39m# If node was already created\u001b[39;00m\n\u001b[1;32m    400\u001b[0m   \u001b[39mif\u001b[39;00m node_id \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloaded_nodes:\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/saving/saved_model/json_utils.py:69\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(json_string)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(json_string):\n\u001b[0;32m---> 69\u001b[0m   \u001b[39mreturn\u001b[39;00m json\u001b[39m.\u001b[39;49mloads(json_string, object_hook\u001b[39m=\u001b[39;49m_decode_helper)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/json/__init__.py:359\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[39mif\u001b[39;00m parse_constant \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m     kw[\u001b[39m'\u001b[39m\u001b[39mparse_constant\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m parse_constant\n\u001b[0;32m--> 359\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\u001b[39m.\u001b[39;49mdecode(s)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, s, _w\u001b[39m=\u001b[39mWHITESPACE\u001b[39m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[39m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[1;32m    338\u001b[0m     end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[39mif\u001b[39;00m end \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(s):\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[39mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "#try:\n",
    "model = tf.keras.models.load_model(f\"models/{model_name}_model\", custom_objects={'localization_loss' : utils.localization_loss})\n",
    "#except Exception as e:\n",
    "#display(f\"There is no model for {model_name} with the error: \\n\\n{e}\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m utils\u001b[39m.\u001b[39mpredict(model\u001b[39m=\u001b[39mmodel, ds\u001b[39m=\u001b[39mds_test)\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "utils.predict(model=model, ds=ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'sa' requires the ipykernel package.\n",
      "\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\n",
      "\u001b[1;31mCommand: 'conda install -n sa ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "utils.predict(model=model, ds=ds_eval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "683ab29619787e7cbb294fc254992704d4e31fd07f214a672985e5126f51fcfb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
